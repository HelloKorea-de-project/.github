# Hello Korea! 🇰🇷 #
## 프로젝트 소개 ##
외국인 대상 종합 여행 정보 플랫폼을 구축해 서울을 여행하려는 외국인에게 다양한 항공편 정보, 여행할 시기에 대한 한국 날씨, 환율 정보 제공과 서울시 자치구별 관광지/행사/숙소 정보를 제공하려고 했습니다. 또한, 데이터 웨어하우스를 구축해 서비스 개선과 마케팅 측면에서 고려할 수 있는 데이터를 분석하려 했습니다

## 구성원 소개 ##
- 김준영: 관광/행사 정보 수집, 대용량 로그 데이터 생성 및 처리
- 신예진: 항공권 정보 수집, 대용량 로그 데이터 생성 및 처리
- 이주영: CI/CD 구성, AWS Infra 구축 및 유지보수/개선
- 정도원: 날씨/숙박 정보 수집, 프로젝트 최적화 및 BI 구성
- 정승현: 환율 정보 수집, CI/CD 구성,웹서버 구축, 프로젝트 최적화 및 BI 구성

## 기술 스택 ##
- 인프라 : AWS, Terraform
- 웹서비스 : Django
- 데이터 엔지니어링 : Apache Airflow, Apache Spark, Amazon Redshift, Amazon RDS, Redis
- 대시보드 구성 : Apache Superset

## 아키텍처 ##
<img width="680" alt="image" src="https://github.com/user-attachments/assets/bf04d8f3-a215-402e-9136-8fa61ce06b9d">

## 데이터 파이프라인 ##
<img width="680" alt="image" src="https://github.com/user-attachments/assets/f094d3f6-8914-4620-8bbd-82121f45f846">

## 웹서비스 구현 ##
1. 데이터 모델링 : 각 페이지에 필요한 데이터를 모델링했습니다
<img width="680" alt="image" src="https://github.com/user-attachments/assets/add27ea5-ff57-4abf-a360-f3580cc632c4">
<br>2. 데이터 수집 : 데이터 모델링을 기반으로 필요한 데이터를 수집해 프로덕션 데이터베이스인 RDS에 적재했습니다
<br>3. 웹사이트 구현 : Django를 이용해 백엔드를 구성했고 

## Airflow ##

## 더미데이터 생성 ##
실제 운영되는 서비스에서는 대량의 데이터가 적재될 것으로 예상되어 더미데이터를 생성했습니다. 항공권 검색/클릭/구매 로그와 사용자 정보, 세션별 채널 & 생성/접속 시각 정보를 생성했습니다
<br><img width="680" alt="image" src="https://github.com/user-attachments/assets/ecd504b9-f4ce-4185-a83c-479342dd2199">

<br> 더미데이터 생성에서 마주친 문제는 다음과 같았습니다.
<br>1. 로컬에서 단일 프로세스로 생성시 대용량 데이터 생성에 상당히 많은 시간이 소요됐습니다. 예시로, 사용자 1000만명 생성시 1시간 10분이 소요됐고 억 단위의 레코드를 생성하려면 더 많은 시간이 소요될 것으로 에상되어 glue의 serverless spark 도입을 결정했습니다. 도입 결과 7개의 인풋 파티션과 5DPU로 시행한 결과 11분이 소요됐습니다

<br>2. 디멘전 테이블로부터 팩트 테이블 생성시 매번 사용자 정보를 샘플링해서 발생시켜 생성 시간이 오래 걸리는 것을 확인했습니다. 이에 검색/클릭/구매 로그와 같은 팩트 테이블을 먼저 생성하고 사용자 정보와 같은 디멘전 테이블을 후에 생성하는 순으로 진행했습니다

<br>3. faker라는 더미데이터 생성 라이브러리를 사용하고 있었는데, faker 사용시 불균등한 현실 데이터와는 달리 균등한 분포의 데이터를 생성한다는 것을 확인했습니다. 이에 현실을 반영하기 위한 불균등한 데이터를 임의로 생성해 추가했습니다

## Redshift ##
더미데이터 생성 후 Redshift 테이블에 실제 쿼리를 실행해 실행 시간을 측정했습니다. 실행 결과 레코드 수 1억개 이상인 테이블에서는 상당한 지연이 발생하는 것으로 관찰되었습니다

<br>이를 해결하기 위해, 다음 두 가지 해결 방안을 생각했습니다

<br>1. 자주 조인되는 키를 sort key(정렬키)로 지정하는 것으로, sort key란 설정한 키를 기준으로 미리 테이블을 정렬해 쿼리시 성능을 향상시키는 방법입니다

<br>2. 자주 스캔되는 테이블을 서브쿼리가 아닌 별도의 테이블로 만들어둠으로써, 같은 쿼리 실행시 성능을 향상시키는 방법입니다

<br>두 가지 해결방안으로 쿼리를 실행한 결과, 전반적으로 테이블 레코드가 1억개 이상인 경우 sort key 설정 전/후, 서브 쿼리 대신 테이블 생성 후 쿼리를 실행한 순으로 점점 성능이 향상되었습니다. 또한 세 개의 테이블을 조인하는 경우엔 더 현저하게 차이가 나는 것을 확인할 수 있었습니다

## Spark ##
Redshift에서 수행했던 대용량 데이터 쿼리들을 Spark에서 수행해 성능을 비교했습니다. 크게는 3가지로 최적화 성능을 비교했습니다

<br>1. 불균등한 분포를 갖는 컬럼 기준으로 파티셔닝, 균등한 분포를 갖는 컬럼 기준으로 파티셔닝
- 하나는 불균등한 데이터 분포를 갖는 출발 공항을 기준으로 파티셔닝했고, 다른 하나는 균등한 데이터 분포를 가지는 사용자 아이디를 기준으로 파티셔닝했습니다. 성능 비교를 위해 채널별 구매수를 연산하는 쿼리를 시행했는데, 불균등한 분포를 가진 출발 공항으로 파티셔닝후 시행한 결과 1분 51초가 소요됐고 균등한 분포를 가진 사용자 아이디로 파티셔닝후 시행한 결과로 1분 33초가 소요됐습니다

<br>2. 쿼리 튜닝 (조인 후 집계, 집계 후 조인 비교)
- 쿼리 최적화 실험을 위해 동일한 결과를 내는 쿼리를 각기 다르게 작성 후 성능을 비교했습니다. 집계하지 않고 바로 조인을 수행했을땐 2분 8초가 소요됐고, 집계 후 조인을 수행했을땐 40초가 더 빠른 1분 28초가 걸리는 것을 확인했습니다. 또한 조인에 해당하는 스테이지를 확인했을때 집계하지 않고 조인 수행 시 2억 8천만 행의 셔플이 발생했고, 집계후 조인시 450만 행의 셔플이 발생한 것을 확인했습니다

<br>3. 셔플 파티션 갯수 최적화
- 셔플 파티션을 임의로 확 줄인 5개로 지정했을 때와 100개로 지정했을때의 성능을 비교했습니다. 셔플 파티션이 5인 경우, 총 4분 33초가 소요됐고, 셔플 파티션이 100인 경우, 훨씬 빠른 2분 4초가 소요된 것을 확인했습니다. 셔플 파티션이 임의로 줄였기 때문에 5개인 경우, 각 태스크마다 3.3GB의 메모리 스필(spill)이 일어났고 반면에, 셔플 파티션이 100인 경우에는 스필(spill)이 발생하지 않은 것을 확인했습니다

## 기능 개선 ##
## 대시보드 구성 ##

## 추후 개선할 사항 ##

프레젠테이션 링크 : https://www.canva.com/design/DAGN4mktO2k/Dpa086pc6QjvBAqSxfpEDw/view?utm_content=DAGN4mktO2k&utm_campaign=designshare&utm_medium=link&utm_source=editor
