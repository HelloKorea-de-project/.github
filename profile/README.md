# Hello Korea! 🇰🇷 #
## 프로젝트 소개 ##
외국인 대상 종합 여행 정보 플랫폼을 구축해 서울을 여행하려는 외국인에게 다양한 항공편 정보, 여행할 시기에 대한 한국 날씨, 환율 정보 제공과 서울시 자치구별 관광지/행사/숙소 정보를 제공하려고 했습니다. 또한, 데이터 웨어하우스를 구축해 서비스 개선과 마케팅 측면에서 고려할 수 있는 데이터를 분석하려 했습니다

## 프로젝트 일정 ##
<img width="680" alt="image" src="https://github.com/user-attachments/assets/10138eb7-5134-4658-9945-10ddd3ec2f01"><br>
- 매일 오후 1시 스크럼을 진행 했습니다.
- 매주 금요일 1주 회고를 진행 했습니다.

## 구성원 소개 ##
- 김준영: 관광/행사 정보 수집, 대용량 로그 데이터 생성 및 처리
- 신예진: 항공권 정보 수집, 대용량 로그 데이터 생성 및 처리
- 이주영: CI/CD 구성, AWS Infra 구축 및 유지보수/개선
- 정도원: 날씨/숙박 정보 수집, 프로젝트 최적화 및 BI 구성
- 정승현: 환율 정보 수집, CI/CD 구성,웹서버 구축, 프로젝트 최적화 및 BI 구성

## 기술 스택 ##
- 인프라 : AWS, Terraform
- 웹서비스 : Django
- 데이터 엔지니어링 : Apache Airflow, Apache Spark, Amazon Redshift, Amazon RDS(Postgres), Redis
- 대시보드 구성 : Apache Superset
- 언어 : Python, SQL, JavaScript

## 아키텍처 ##
<img src="https://github.com/user-attachments/assets/496678f6-663b-4061-8159-e9583af601bb" width="750">


## 데이터 파이프라인 ##
<img width="680" alt="image" src="https://github.com/user-attachments/assets/f094d3f6-8914-4620-8bbd-82121f45f846">

## 웹서비스 구현 ##
1. 데이터 모델링 : 각 페이지에 필요한 데이터를 모델링했습니다.
<img width="680" alt="image" src="https://github.com/user-attachments/assets/add27ea5-ff57-4abf-a360-f3580cc632c4">
<br>2. 데이터 수집 : 데이터 모델링을 기반으로 필요한 데이터를 수집해 프로덕션 데이터베이스인 RDS에 적재했습니다.
<br>3. 웹사이트 구현 : EC2에 Django를 올려서 백엔드를 구성했고 AWS RDS(Postgres)를 Production DB로 사용했습니다. 한국 관광을 원하는 외국인을 위한 웹페이지를 구성하고자 했고, 국내 공항으로의 항공 운항 정보를 확인할 수 있는 페이지와 서울시 내 전체적인 관광 정보들을 확인할 수 있는 페이지를 구성하였습니다. 

## Airflow ##
<img width="680" alt="image" src="https://github.com/user-attachments/assets/1bf8e468-96b1-4e2c-ad43-23900fec8bf1">
<br>각각의 데이터 수집처마다 DAG를 작성했고, 크게는 항공권/날씨/환율/투어 정보로 나뉩니다.
<br>1. 항공권은 공공 데이터 포털 API를 이용한 인천공항에 취항한 공항 정보(service_airport_to_ICN), 운항 계획 수(arr_count_to_ICN), APIFY를 이용해 항공권 정보를 가져오는(flight_price)로 구성되어 있습니다.
<br>2. 환율은 공공 데이터 포털 API를 이용했습니다. 새로운 데이터가 업데이트되는 평일 오전 11시 이후에 주기적으로 가져오도록 구성했습니다.
<br>3. 관광 정보는 한국관광공사 API를 이용했습니다. 데이터는 위치와 카테고리 등을 포함한 관광지 정보를 수집하며, 수집한 데이터를 각 단계에 맞게 처리하여 S3, Redshift, RDS에 적재합니다.
<br>4. 축제(공연) 정보는 KOPIS API를 이용했습니다. 데이터는 공연장 정보와 일정과 내용을 포함한 축제(공연)정보를 수집하며, 수집한 데이터를 각 단계에 맞게 처리하여 S3, Redshift, RDS에 적재합니다.

## 더미데이터 생성 ##
실제 운영되는 서비스에서는 대량의 데이터가 적재될 것으로 예상되어 더미데이터를 생성했습니다. 항공권 검색/클릭/구매 로그와 사용자 정보, 세션별 채널 & 생성/접속 시각 정보를 생성했습니다
<br><img width="680" alt="image" src="https://github.com/user-attachments/assets/ecd504b9-f4ce-4185-a83c-479342dd2199">

<br> 더미데이터 생성에서 마주친 문제는 다음과 같았습니다.
<br>1. 로컬에서 단일 프로세스로 생성시 대용량 데이터 생성에 상당히 많은 시간이 소요됐습니다. 예시로, 사용자 1000만명 생성시 1시간 10분이 소요됐고 억 단위의 레코드를 생성하려면 더 많은 시간이 소요될 것으로 에상되어 glue의 serverless spark 도입을 결정했습니다. 도입 결과 7개의 인풋 파티션과 5DPU로 시행한 결과 11분이 소요됐습니다

<br>2. 디멘전 테이블로부터 팩트 테이블 생성시 매번 사용자 정보를 샘플링해서 발생시켜 생성 시간이 오래 걸리는 것을 확인했습니다. 이에 검색/클릭/구매 로그와 같은 팩트 테이블을 먼저 생성하고 사용자 정보와 같은 디멘전 테이블을 후에 생성하는 순으로 진행했습니다

<br>3. faker라는 더미데이터 생성 라이브러리를 사용하고 있었는데, faker 사용시 불균등한 현실 데이터와는 달리 균등한 분포의 데이터를 생성한다는 것을 확인했습니다. 이에 현실을 반영하기 위한 불균등한 데이터를 임의로 생성해 추가했습니다

## Redshift ##
더미데이터 생성 후 Redshift 테이블에 실제 쿼리를 실행해 실행 시간을 측정했습니다. 실행 결과 레코드 수 1억개 이상인 테이블에서는 상당한 지연이 발생하는 것으로 관찰되었습니다

<br>이를 해결하기 위해, 다음 두 가지 해결 방안을 생각했습니다

<br>1. 자주 조인되는 키를 sort key(정렬키)로 지정하는 것으로, sort key란 설정한 키를 기준으로 미리 테이블을 정렬해 쿼리시 성능을 향상시키는 방법입니다

<br>2. 자주 스캔되는 테이블을 서브쿼리가 아닌 별도의 테이블로 만들어둠으로써, 같은 쿼리 실행시 성능을 향상시키는 방법입니다

<br>두 가지 해결방안으로 쿼리를 실행한 결과, 전반적으로 테이블 레코드가 1억개 이상인 경우 sort key 설정 전/후, 서브 쿼리 대신 테이블 생성 후 쿼리를 실행한 순으로 점점 성능이 향상되었습니다. 또한 세 개의 테이블을 조인하는 경우엔 더 현저하게 차이가 나는 것을 확인할 수 있었습니다

## Spark ##
Redshift에서 수행했던 대용량 데이터 쿼리들을 Spark에서 수행해 성능을 비교했습니다. 크게는 3가지로 최적화 성능을 비교했습니다

<br>1. 불균등한 분포를 갖는 컬럼 기준으로 파티셔닝, 균등한 분포를 갖는 컬럼 기준으로 파티셔닝
- 하나는 불균등한 데이터 분포를 갖는 출발 공항을 기준으로 파티셔닝했고, 다른 하나는 균등한 데이터 분포를 가지는 사용자 아이디를 기준으로 파티셔닝했습니다. 성능 비교를 위해 채널별 구매수를 연산하는 쿼리를 시행했는데, 불균등한 분포를 가진 출발 공항으로 파티셔닝후 시행한 결과 1분 51초가 소요됐고 균등한 분포를 가진 사용자 아이디로 파티셔닝후 시행한 결과로 1분 33초가 소요됐습니다

<br>2. 쿼리 튜닝 (조인 후 집계, 집계 후 조인 비교)
- 쿼리 최적화 실험을 위해 동일한 결과를 내는 쿼리를 각기 다르게 작성 후 성능을 비교했습니다. 집계하지 않고 바로 조인을 수행했을땐 2분 8초가 소요됐고, 집계 후 조인을 수행했을땐 40초가 더 빠른 1분 28초가 걸리는 것을 확인했습니다. 또한 조인에 해당하는 스테이지를 확인했을때 집계하지 않고 조인 수행 시 2억 8천만 행의 셔플이 발생했고, 집계후 조인시 450만 행의 셔플이 발생한 것을 확인했습니다

<br>3. 셔플 파티션 갯수 최적화
- 크게 쿼리 최적화 전 셔플 파티션 최적화와 쿼리 최적화 후 셔플 파티션 최적화 실험을 진행했습니다. 

## 기능 개선 ##
ETL 과정에서의 예상치 못한 오류나 예외로 인해 데이터 품질이 저하될 수 있는 가능성이 있음을 인지하고 이를 예방하고자 DBT로 데이터 모델 품질 평가(유닛 테스트)를 구성했습니다.

<img width="680" alt="image" src="https://github.com/user-attachments/assets/f526bd95-84b5-4ea2-a005-ce010c2c02de">

1. Airflow DAG를 통해 데이터 업데이트 시 새로 수입된 데이터 모델 테스트(정합성, 도메인 무결성, 개체 무결성) 및 품질 저하 알림을 자동화 했습니다.<br>
2. Github를 통한 데이터 모델 문서 버전 관리, generic test 및 macro를 활용한 테스트 코드 관리를 구성했습니다.<br>
3. 데이터 모델마다의 freshness field를 선정하고, 해당 field에 의해 필터링된 fresh 데이터 모델을 정의하여 이를 대상으로 테스트하는 방식으로 구현했습니다.


BI tool(Superset)에 차트로 시각화된 데이터가 어떤 과정으로 만들어졌는지, 무엇을 분석하기 위해 만들어졌는지 파악하기 힘들다는 점을 인지하고,
<br>Redshift에서 ELT를 통해 만들어지는 데이터 모델들을 DBT에 관리하여 데이터 모델 버전, 각 모델들의 메타 정보, 모델 간 종속 관계를 쉽게 파악할 수 있도록 했습니다.

<img width="680" alt="image" src="https://github.com/user-attachments/assets/af3f1b23-e123-4120-bf4b-7b5b5b91cde2">
<img width="680" alt="image" src="https://github.com/user-attachments/assets/ab98dc95-658b-4c0d-9e8d-29631eee33c5">

위의 이미지들은 Airflow 웹페이지의 ‘dbt docs’ 메뉴를 들어가면 확인할 수 있는 화면이며, 데이터 모델을 검색하고 정보를 확인할 수 있습니다.
<br>DBT를 도입하는 과정 중에 모델 생성까지의 실행 시간이 많이 걸리는 쿼리, 불필요하게 중복되거나 종속된 쿼리, 실행이 되지 않는 쿼리 등을 발견할 수 있었고 이들을 정리 및 개선할 수 있었습니다.


## 대시보드 구성 ##

대시 보드는 서비스 데이터 분석, 사용자 분석으로 분류해 구성했습니다.
**서비스 데이터 분석**에서는 지역구별 관광지/행사/숙소 정보에 대한 차트와 지도를 통한 분포를 확인할 수 있고, 계절별 행사 분포, 날씨 추이와 날씨에 따른 항공권 분포 등을 확인할 수 있습니다.

<img width="680" alt="image" src="https://github.com/user-attachments/assets/81a1d300-9d38-4541-9995-2a17a7125261">

<br>**사용자 분석**에서는 생성한 더미데이터를 사용했고, 유입 채널/국가/연령대별 분포와 항공권 검색부터 결제까지 걸린 시간, 가장 많이 검색된 공항 등을 확인할 수 있습니다.

<img width="680" alt="image" src="https://github.com/user-attachments/assets/99d6d9aa-51e9-4809-9517-486685655770">

## 추후 개선할 사항 ##

프레젠테이션 링크 : https://www.canva.com/design/DAGN4mktO2k/Dpa086pc6QjvBAqSxfpEDw/view?utm_content=DAGN4mktO2k&utm_campaign=designshare&utm_medium=link&utm_source=editor<br>
보고서 링크 : https://www.notion.so/prgrms/5c9e91b238fc4aaf8eefedab0b66688e?pvs=4
